# Generic Autonomous Vehicle System
Pose estimation for autonomous vehicles using road signs. Not very user-friendly at the moment.

# How It Works
## Hardware
I chose to use two generic usb webcams in a stereo configuration with a baseline of ~190.5 millimeters. 
This allows us to do basic depth estimation using the difference between the two images.
Camera calibration constants can be found in the [rightCameraProperties.json](cameraCalib/rightCameraProperties.json) and the [leftCameraProperties.json](cameraCalib/leftCameraProperties.json) files respectively.
The other json files were generated by [calibdb.net](https://www.calibdb.net/#).
I've also chosen to use a [SLAMTEC RP LiDAR A1](https://www.slamtec.ai/product/slamtec-rplidar-a1/) rotating LiDAR for more accurate depth perception when available.
![Setup Without LiDAR](assets/Setup_No_LiDAR.JPEG)
![Setup With LiDAR](assets/Setup_With_LiDAR.JPEG)
## Software
### Sign Detection
Sign detection is done using a pre-trained YOLOv8 model for each camera.